{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quickstart"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Indexing: Load"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to first load the blog post contents. We can use DocumentLoaders for this, which are objects that load in data from a source and return a list of Documents. A `Document` is an object with some `page_content` (str) and `metadata` (dict).\n",
    "\n",
    "In this case we’ll use the WebBaseLoader, which uses `urllib` to load HTML from web URLs and `BeautifulSoup` to parse it to text. We can customize the HTML -> text parsing by passing in parameters to the `BeautifulSoup` parser via `bs_kwargs` (see BeautifulSoup docs). In this case only HTML tags with class “post-content”, “post-title”, or “post-header” are relevant, so we’ll remove all others."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-14T22:18:25.514812500Z",
     "start_time": "2024-03-14T22:18:21.540856300Z"
    }
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Create a persistent chromaDB client\n",
    "client = chromadb.PersistentClient(path=\"C:\\\\Users\\\\jnsep\\\\OneDrive\\\\Desktop\\\\Projects\\\\ChromaDB_storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# client.reset() # Empties and completely resets the database. ⚠️ This is destructive and not reversible."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T22:18:25.530491500Z",
     "start_time": "2024-03-14T22:18:25.514812500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Load a document from the web\n",
    "\n",
    "# # Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T22:25:41.154430500Z",
     "start_time": "2024-03-14T22:25:40.994537300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "42824"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T22:26:07.451145800Z",
     "start_time": "2024-03-14T22:26:07.435476100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# # # Load a pdf file\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "#\n",
    "# loader = PyPDFLoader(\"la_trama_de_la_vida.pdf\")\n",
    "# docs = loader.load_and_split()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T22:25:15.457468500Z",
     "start_time": "2024-03-14T22:25:04.862269200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "42824"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T22:25:44.335855100Z",
     "start_time": "2024-03-14T22:25:44.304559200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T22:25:47.512541600Z",
     "start_time": "2024-03-14T22:25:47.481259600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Indexing: Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our loaded document is over 42k characters long. This is too long to fit in the context window of many models. Even for those models that could fit the full post in their context window, models can struggle to find information in very long inputs.\n",
    "\n",
    "To handle this we’ll split the `Document` into chunks for embedding and vector storage. This should help us retrieve only the most relevant bits of the blog post at run time.\n",
    "\n",
    "In this case we’ll split our documents into chunks of 1000 characters with 200 characters of overlap between chunks. The overlap helps mitigate the possibility of separating a statement from important context related to it. We use the RecursiveCharacterTextSplitter, which will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.\n",
    "\n",
    "We set `add_start_index=True` so that the character index at which each split Document starts within the initial Document is preserved as metadata attribute “start_index”."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:09:38.009799700Z",
     "start_time": "2024-03-14T04:09:37.952254900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "213"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000, chunk_overlap=300, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "len(all_splits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:09:39.477531900Z",
     "start_time": "2024-03-14T04:09:39.465004600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "langchain_core.documents.base.Document"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_splits[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:36:36.054819900Z",
     "start_time": "2024-03-14T04:36:36.038111100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "464"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits[0].page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:09:43.576302300Z",
     "start_time": "2024-03-14T04:09:43.559320Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "{'source': 'la_trama_de_la_vida.pdf', 'page': 0, 'start_index': 0}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0].metadata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:09:55.055207500Z",
     "start_time": "2024-03-14T04:09:55.041177800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Indexing: Store\n",
    "\n",
    "Now we need to index our 66 text chunks so that we can search over them at runtime. The most common way to do this is to embed the contents of each document split and insert these embeddings into a vector database (or vector store). When we want to search over our splits, we take a text search query, embed it, and perform some sort of “similarity” search to identify the stored splits with the most similar embeddings to our query embedding. The simplest similarity measure is cosine similarity — we measure the cosine of the angle between each pair of embeddings (which are high dimensional vectors).\n",
    "\n",
    "We can embed and store all of our document splits in a single command using the Chroma vector store and OpenAIEmbeddings model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:10:06.147996200Z",
     "start_time": "2024-03-14T04:09:57.553205100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "langchain_community.vectorstores.chroma.Chroma"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vectorstore)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:45:49.456565600Z",
     "start_time": "2024-03-14T04:45:49.440525200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Retrieval and Generation: Retrieve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let’s write the actual application logic. We want to create a simple application that takes a user question, searches for documents relevant to that question, passes the retrieved documents and initial question to a model, and returns an answer.\n",
    "\n",
    "First we need to define our logic for searching over documents. LangChain defines a Retriever interface which wraps an index that can return relevant `Documents` given a string query.\n",
    "\n",
    "The most common type of `Retriever` is the VectorStoreRetriever, which uses the similarity search capabilities of a vector store to facilitate retrieval. Any `VectorStore` can easily be turned into a `Retriever` with `VectorStore.as_retriever()`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:37.402350800Z",
     "start_time": "2024-03-14T04:13:37.395351300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What are the approaches to Task Decomposition?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:38.198063200Z",
     "start_time": "2024-03-14T04:13:37.889349500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:38.296972500Z",
     "start_time": "2024-03-14T04:13:38.287426400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102. \n",
      "danov fue el primero en intentar la integración de los conceptos de organización,  \n",
      "patrón y complejidad en una teoría de sistemas coherente. Los cibernéticos se centraron en los patrones de comunicación y control –en particular en las pautas de circularidad causal subyacentes en el concepto de retroalimentación–, y al ha\n",
      "  \n",
      "cerlo, fueron los primeros en distinguir claramente el patrón de organización de un sistema, de su estructura física.  Las \n",
      "<<piezas del rompecabezas >> que faltaban –el concepto de autoorganización \n",
      "y las nuevas matemáticas de la complejidad– han sido identificadas y analizadas a lo largo de los últimos veinte años del siglo XX. Una vez más, la noción de patrón ha sido fundamental para ambos acontecimientos. El concepto de autoorganiza-ción se originó en el reconocimiento de la red como patrón general de vida, refina-do posteriormente por Maturana y Varela en su concepto de autopoiesis. Las nue-vas matemáticas de la complejidad son esencialmente unas matemáticas de patro\n",
      " \n",
      "nes visuales –atractores extraños, retratos fase, fractales, etc.– que se analizan dentro del marco de la topología planteado por Poincaré.  La comprensión del patrón\n",
      " será pues de crucial importancia para la comprensión \n",
      "científica de la vida. No obstante, para el completo entendimiento de un sistema vivo, la comprensión de su patrón de organización –si bien criticamente importante – no resulta suficiente. Necesitamos también comprender la estructura del siste-\n",
      "ma. De hecho, hemos visto cómo el estudio de la estructura ha sido el principal \n",
      "planteamiento de la ciencia occidental, eclipsando una y otra vez el estudio del patrón.  He llegado a la convicción de que la clave para una teoría complet de los siste-mas vivos estriba precisamente en la síntesis de etos dos planteamientos: el es-tudio del patrón (forma, orden, cualidad) y el de la estructura (substancia, materia, cantidad). Seguiré a Humberto Maturana y a Francisco Varela en sus definiciones para ambos criterios clave de un sistema vivo: su patrón de organización y su estructura \n",
      "(Maturana y Varela, 1987, p. 47. En lugar de <<patrón de organización >>, los \n",
      "autores utilizan simplemente el término  <<organización >>). El patrón de organización de \n",
      "cualquier sistema, vivo o no, es la configuración de las relaciones entre sus compo  \n",
      "nentes, que determina las características esenciales del sistema. Dicho de otro mo  \n",
      "do, ciertas relaciones deben estar presentes para que algo sea reconocible como una silla, una bicicleta o un árbol. Esta configuración de relaciones que le otorga al sistema sus característivcas esenciales, es lo que entendemos como su patrón\n",
      " de \n",
      "organización . \n",
      " La estructura  de un sistema es la corporeización física de su patrón de organiza-\n",
      "ción. Mientras que la descripción del patrón de organización implica una cartogra-fía abstracta de relaciones, la descripción de la estructura implica la de sus compo\n",
      " \n",
      "nentes físicos presentes: sus formas, sus composiciones químicas, etc.  Para ilustrar la diferencia entre patrón y estructura, tomemos un sistema no vivo bien conocido: una bicicleta. Para que algo pueda ser llamado una bicicleta, debe-rá existir un número de relaciones funcionales entre sus componentes conocidos como cuadro, pedales, manillar, ruedas, cadenas, ruedas dentadas, etc. La confi-guración completa de estas relaciones funcionales\n",
      " constituye el patrón de organi-\n",
      "zación de la bicicleta.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:40.015525Z",
     "start_time": "2024-03-14T04:13:39.968065200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "langchain_core.vectorstores.VectorStoreRetriever"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(retriever)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:03:55.981925700Z",
     "start_time": "2024-03-14T05:03:55.919219400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Retrieval and Generation: Generate\n",
    "\n",
    "Let’s put it all together into a chain that takes a question, retrieves relevant documents, constructs a prompt, passes that to a model, and parses the output.\n",
    "\n",
    "We’ll use the gpt-3.5-turbo OpenAI chat model, but any LangChain `LLM` or `ChatModel` could be substituted in."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:47.114046100Z",
     "start_time": "2024-03-14T04:13:47.069345400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:49.690772100Z",
     "start_time": "2024-03-14T04:13:47.373462400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: filler question \\nContext: filler context \\nAnswer:\")]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "example_messages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:49.710859400Z",
     "start_time": "2024-03-14T04:13:49.691774300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(example_messages[0].content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:49.753274400Z",
     "start_time": "2024-03-14T04:13:49.710859400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# rag_chain = (\n",
    "#     {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:49.753274400Z",
     "start_time": "2024-03-14T04:13:49.728633200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# for chunk in rag_chain.stream(\"What is Task Decomposition?\"):\n",
    "#     print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:13:50.365556Z",
     "start_time": "2024-03-14T04:13:50.354006100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\" Usa el contexto proporcionado para responder la pregunta que del final.\n",
    "Si no sabes la respuesta a la pregunta, simplemente responde \"No sé\", no intentes inventar una respuesta.\n",
    "Si la información del cntexto no es suficiente para responder la pregunta, responde \"No tengo información suficiente para responder\".\n",
    "Utiliza máximo cuatro (4) oraciones y responde de la manera más concisa posible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:23:27.777186200Z",
     "start_time": "2024-03-14T04:23:27.755135300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "'La crisis de percepción se refiere a la falta de comprensión y conciencia de la interconexión y la interdependencia de los problemas globales que enfrentamos en la actualidad. Esta crisis surge de una visión desfasada del mundo, que no es adecuada para abordar los desafíos de un mundo superpoblado y globalmente interconectado. Para superar esta crisis, es necesario un cambio radical en la percepción, el pensamiento y los valores de la sociedad.'"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Explica la crisis de percepción\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:17:13.083651400Z",
     "start_time": "2024-03-14T04:17:10.064963800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "'Una posible causa de la crisis de percepción es la visión desfasada del mundo que suscriben la mayoría de las personas y grandes instituciones sociales.'"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Cuál es una posible causa de la crisis de percepción?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:18:17.931002900Z",
     "start_time": "2024-03-14T04:18:16.008472100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "'Los criterios clave de un sistema vivo son el patrón de organización, la estructura y el proceso vital. Estos criterios se basan en la autopoiesis, la estructura disipativa y la cognición.'"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Cuáles son los criterios clave de un sistema vivo?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:20:30.906590800Z",
     "start_time": "2024-03-14T04:20:28.296720200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "'No tengo información suficiente para responder.'"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Cuál es la masa del sol?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:09:48.730402100Z",
     "start_time": "2024-03-14T05:09:47.271448400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "langchain_core.runnables.base.RunnableSequence"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rag_chain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:04:19.922548500Z",
     "start_time": "2024-03-14T05:04:19.910535500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
